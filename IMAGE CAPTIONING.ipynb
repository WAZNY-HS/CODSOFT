{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6977e008",
   "metadata": {},
   "source": [
    "# Created by: Shaffon Wazny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-trained VGG model (excluding classification head)\n",
    "base_model = VGG16(weights='imagenet')\n",
    "image_model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ed94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and encode an image\n",
    "def preprocess_and_encode_image(img_path):\n",
    "    img = Image.open(requests.get(img_path, stream=True).raw)\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img)\n",
    "    img_array = preprocess_input(img_array.reshape(1, 224, 224, 3))\n",
    "    return image_model.predict(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c181aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample image URL\n",
    "sample_image_url = 'https://res.cloudinary.com/cloudinary-marketing/images/w_2000,h_1100/f_auto,q_auto/v1686254465/Blog-Ai-image-captioning/Blog-Ai-image-captioning-jpg?_i=AA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the image encoding function\n",
    "encoded_image = preprocess_and_encode_image(sample_image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and preprocess the MS COCO dataset (captions and images)\n",
    "# Build tokenizers for captions\n",
    "tokenizer = Tokenizer()\n",
    "captions = [\"a sample caption 1\", \"another example caption 2\", ...]  # Replace with your captions\n",
    "tokenizer.fit_on_texts(captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert captions to sequences\n",
    "sequences = tokenizer.texts_to_sequences(captions)\n",
    "max_sequence_length = max(len(seq) for seq in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce467ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the captioning model\n",
    "embedding_dim = 256\n",
    "units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = layers.Input(shape=(4096,))\n",
    "encoder = layers.Dense(embedding_dim, activation='relu')(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = layers.Input(shape=(None,))\n",
    "decoder_embedding = layers.Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = layers.LSTM(units, return_sequences=True, return_state=True)(decoder_embedding, initial_state=[encoder])\n",
    "decoder_outputs = layers.Dense(vocab_size, activation='softmax')(decoder_lstm[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f250a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ab483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80057e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (replace with your actual training data)\n",
    "# model.fit([encoded_images, padded_sequences[:, :-1]], padded_sequences[:, 1:], epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# Generate captions for a new image\n",
    "def generate_caption(image_url):\n",
    "    encoded_image = preprocess_and_encode_image(image_url)\n",
    "    initial_state = [encoded_image.reshape(1, -1), np.zeros((1, units)), np.zeros((1, units))]\n",
    "    \n",
    "    # Generate caption using the trained model (replace with your actual model)\n",
    "    # predicted_sequence = generate_caption_sequence(model, initial_state)\n",
    "    \n",
    "    # Convert predicted sequence back to text\n",
    "    # predicted_caption = sequence_to_text(predicted_sequence)\n",
    "    \n",
    "    return predicted_caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562296d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the image caption generation function\n",
    "generated_caption = generate_caption(sample_image_url)\n",
    "print(\"Generated Caption:\", generated_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f00d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
